{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Machine Learning with Apache Spark.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANK7QPeg3KjK",
        "outputId": "ba25d8a6-6f96-4737-c679-30dad36b4d10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.7/dist-packages (3.2.1)\n",
            "Requirement already satisfied: py4j==0.10.9.3 in /usr/local/lib/python3.7/dist-packages (from pyspark) (0.10.9.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# importing module\n",
        "import pyspark\n",
        "\n",
        "# importing sparksession from \n",
        "# pyspark.sql module\n",
        "#pyspark.sql.SparkSession Main entry point for DataFrame and SQL functionality\n",
        "#pyspark.sql.DataFrame A distributed collection of data grouped into named columns\n",
        "#pyspark.sql.SparkSession(sparkContext, jsparkSession=None)[source]\n",
        "#The entry point to programming Spark with the Dataset and DataFrame API.\n",
        "#A SparkSession can be used create DataFrame, register DataFrame as tables, execute SQL over tables, cache tables, and read parquet files.\n",
        "from pyspark.sql import SparkSession\n",
        "  \n",
        "# creating sparksession and giving \n",
        "# an app name\n",
        "\n",
        "#builder: A class attribute having a Builder to construct SparkSession instances\n",
        "#appName(name)[source] Sets a name for the application, which will be shown in the Spark web UI.\n",
        "#If no application name is set, a randomly generated name will be used.\n",
        "\n",
        "#getOrCreate()[source]\n",
        "#Gets an existing SparkSession or, if there is no existing one, creates a new one based on the options set in this builder.\n",
        "#This method first checks whether there is a valid global default SparkSession, and if yes, return that one. If no valid global default SparkSession exists, the method creates a new SparkSession and assigns the newly created SparkSession as the global default.\n",
        "\n",
        "spark = SparkSession.builder.appName('sparkdf').getOrCreate()"
      ],
      "metadata": {
        "id": "C1eL29FahdSd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Data Loading and Data Framing**"
      ],
      "metadata": {
        "id": "WVl3nJhmexdW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas.compat.numpy import np_datetime64_compat\n",
        "from sklearn.datasets import load_iris\n",
        "from pyspark.ml.linalg import Vectors\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "#load iris dataset\n",
        "iris_data = load_iris()\n",
        "#Classes 3\n",
        "#Samples per class 50\n",
        "#Samples total 150\n",
        "#Dimensionality 4\n",
        "#Features real, positive\n",
        "#print(iris_data.data)\n",
        "groundtruth=iris_data.target\n",
        "features=iris_data.data\n",
        "#print(type(groundtruth))\n",
        "#print(groundtruth.shape,features.shape)\n",
        "print(groundtruth)\n",
        "print(features)\n",
        "\n",
        "\n",
        "b=groundtruth.reshape((len(groundtruth),1))\n",
        "#print(b.shape)\n",
        "data=np.concatenate((b,iris_data.data), axis = 1)\n",
        "print(data)\n",
        "\n",
        "#print(data)\n",
        "\n",
        "#iris label with data\n",
        "dff = map(lambda x: (int(x[0]), Vectors.dense(x[1:])), data)\n",
        "\n",
        "#dff = map(lambda x: (int(x[0]),Vectors.dense(x)), iris_data.data)\n",
        "columns = [\"label\", \"features\"]\n",
        "#df = pd.DataFrame(iris_data.data, columns=list('abcd'))\n",
        "mydf = spark.createDataFrame(dff,columns)\n",
        "# show data frame\n",
        "mydf.show(150)\n",
        "\n",
        "\n",
        "\n",
        "# Prepare test data\n",
        "my_test = spark.createDataFrame([\n",
        "    (0.0, Vectors.dense([4.6, 3.1, 1.5, 0.2])),\n",
        "    (0.0, Vectors.dense([5.4, 3.7, 1.5, 0.2])),\n",
        "    (1.0, Vectors.dense([5.9,3.2,4.8,1.8])),\n",
        "    (1.0, Vectors.dense([6.3,2.5,4.9,1.5])),\n",
        "    (2.0, Vectors.dense([6.7,3.3,5.7,2.5]))], [\"label\", \"features\"])\n",
        "\n"
      ],
      "metadata": {
        "id": "e0BDiKEzhXFJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83318424-b30f-48d0-c21d-2c1ba20e4567"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2]\n",
            "[[5.1 3.5 1.4 0.2]\n",
            " [4.9 3.  1.4 0.2]\n",
            " [4.7 3.2 1.3 0.2]\n",
            " [4.6 3.1 1.5 0.2]\n",
            " [5.  3.6 1.4 0.2]\n",
            " [5.4 3.9 1.7 0.4]\n",
            " [4.6 3.4 1.4 0.3]\n",
            " [5.  3.4 1.5 0.2]\n",
            " [4.4 2.9 1.4 0.2]\n",
            " [4.9 3.1 1.5 0.1]\n",
            " [5.4 3.7 1.5 0.2]\n",
            " [4.8 3.4 1.6 0.2]\n",
            " [4.8 3.  1.4 0.1]\n",
            " [4.3 3.  1.1 0.1]\n",
            " [5.8 4.  1.2 0.2]\n",
            " [5.7 4.4 1.5 0.4]\n",
            " [5.4 3.9 1.3 0.4]\n",
            " [5.1 3.5 1.4 0.3]\n",
            " [5.7 3.8 1.7 0.3]\n",
            " [5.1 3.8 1.5 0.3]\n",
            " [5.4 3.4 1.7 0.2]\n",
            " [5.1 3.7 1.5 0.4]\n",
            " [4.6 3.6 1.  0.2]\n",
            " [5.1 3.3 1.7 0.5]\n",
            " [4.8 3.4 1.9 0.2]\n",
            " [5.  3.  1.6 0.2]\n",
            " [5.  3.4 1.6 0.4]\n",
            " [5.2 3.5 1.5 0.2]\n",
            " [5.2 3.4 1.4 0.2]\n",
            " [4.7 3.2 1.6 0.2]\n",
            " [4.8 3.1 1.6 0.2]\n",
            " [5.4 3.4 1.5 0.4]\n",
            " [5.2 4.1 1.5 0.1]\n",
            " [5.5 4.2 1.4 0.2]\n",
            " [4.9 3.1 1.5 0.2]\n",
            " [5.  3.2 1.2 0.2]\n",
            " [5.5 3.5 1.3 0.2]\n",
            " [4.9 3.6 1.4 0.1]\n",
            " [4.4 3.  1.3 0.2]\n",
            " [5.1 3.4 1.5 0.2]\n",
            " [5.  3.5 1.3 0.3]\n",
            " [4.5 2.3 1.3 0.3]\n",
            " [4.4 3.2 1.3 0.2]\n",
            " [5.  3.5 1.6 0.6]\n",
            " [5.1 3.8 1.9 0.4]\n",
            " [4.8 3.  1.4 0.3]\n",
            " [5.1 3.8 1.6 0.2]\n",
            " [4.6 3.2 1.4 0.2]\n",
            " [5.3 3.7 1.5 0.2]\n",
            " [5.  3.3 1.4 0.2]\n",
            " [7.  3.2 4.7 1.4]\n",
            " [6.4 3.2 4.5 1.5]\n",
            " [6.9 3.1 4.9 1.5]\n",
            " [5.5 2.3 4.  1.3]\n",
            " [6.5 2.8 4.6 1.5]\n",
            " [5.7 2.8 4.5 1.3]\n",
            " [6.3 3.3 4.7 1.6]\n",
            " [4.9 2.4 3.3 1. ]\n",
            " [6.6 2.9 4.6 1.3]\n",
            " [5.2 2.7 3.9 1.4]\n",
            " [5.  2.  3.5 1. ]\n",
            " [5.9 3.  4.2 1.5]\n",
            " [6.  2.2 4.  1. ]\n",
            " [6.1 2.9 4.7 1.4]\n",
            " [5.6 2.9 3.6 1.3]\n",
            " [6.7 3.1 4.4 1.4]\n",
            " [5.6 3.  4.5 1.5]\n",
            " [5.8 2.7 4.1 1. ]\n",
            " [6.2 2.2 4.5 1.5]\n",
            " [5.6 2.5 3.9 1.1]\n",
            " [5.9 3.2 4.8 1.8]\n",
            " [6.1 2.8 4.  1.3]\n",
            " [6.3 2.5 4.9 1.5]\n",
            " [6.1 2.8 4.7 1.2]\n",
            " [6.4 2.9 4.3 1.3]\n",
            " [6.6 3.  4.4 1.4]\n",
            " [6.8 2.8 4.8 1.4]\n",
            " [6.7 3.  5.  1.7]\n",
            " [6.  2.9 4.5 1.5]\n",
            " [5.7 2.6 3.5 1. ]\n",
            " [5.5 2.4 3.8 1.1]\n",
            " [5.5 2.4 3.7 1. ]\n",
            " [5.8 2.7 3.9 1.2]\n",
            " [6.  2.7 5.1 1.6]\n",
            " [5.4 3.  4.5 1.5]\n",
            " [6.  3.4 4.5 1.6]\n",
            " [6.7 3.1 4.7 1.5]\n",
            " [6.3 2.3 4.4 1.3]\n",
            " [5.6 3.  4.1 1.3]\n",
            " [5.5 2.5 4.  1.3]\n",
            " [5.5 2.6 4.4 1.2]\n",
            " [6.1 3.  4.6 1.4]\n",
            " [5.8 2.6 4.  1.2]\n",
            " [5.  2.3 3.3 1. ]\n",
            " [5.6 2.7 4.2 1.3]\n",
            " [5.7 3.  4.2 1.2]\n",
            " [5.7 2.9 4.2 1.3]\n",
            " [6.2 2.9 4.3 1.3]\n",
            " [5.1 2.5 3.  1.1]\n",
            " [5.7 2.8 4.1 1.3]\n",
            " [6.3 3.3 6.  2.5]\n",
            " [5.8 2.7 5.1 1.9]\n",
            " [7.1 3.  5.9 2.1]\n",
            " [6.3 2.9 5.6 1.8]\n",
            " [6.5 3.  5.8 2.2]\n",
            " [7.6 3.  6.6 2.1]\n",
            " [4.9 2.5 4.5 1.7]\n",
            " [7.3 2.9 6.3 1.8]\n",
            " [6.7 2.5 5.8 1.8]\n",
            " [7.2 3.6 6.1 2.5]\n",
            " [6.5 3.2 5.1 2. ]\n",
            " [6.4 2.7 5.3 1.9]\n",
            " [6.8 3.  5.5 2.1]\n",
            " [5.7 2.5 5.  2. ]\n",
            " [5.8 2.8 5.1 2.4]\n",
            " [6.4 3.2 5.3 2.3]\n",
            " [6.5 3.  5.5 1.8]\n",
            " [7.7 3.8 6.7 2.2]\n",
            " [7.7 2.6 6.9 2.3]\n",
            " [6.  2.2 5.  1.5]\n",
            " [6.9 3.2 5.7 2.3]\n",
            " [5.6 2.8 4.9 2. ]\n",
            " [7.7 2.8 6.7 2. ]\n",
            " [6.3 2.7 4.9 1.8]\n",
            " [6.7 3.3 5.7 2.1]\n",
            " [7.2 3.2 6.  1.8]\n",
            " [6.2 2.8 4.8 1.8]\n",
            " [6.1 3.  4.9 1.8]\n",
            " [6.4 2.8 5.6 2.1]\n",
            " [7.2 3.  5.8 1.6]\n",
            " [7.4 2.8 6.1 1.9]\n",
            " [7.9 3.8 6.4 2. ]\n",
            " [6.4 2.8 5.6 2.2]\n",
            " [6.3 2.8 5.1 1.5]\n",
            " [6.1 2.6 5.6 1.4]\n",
            " [7.7 3.  6.1 2.3]\n",
            " [6.3 3.4 5.6 2.4]\n",
            " [6.4 3.1 5.5 1.8]\n",
            " [6.  3.  4.8 1.8]\n",
            " [6.9 3.1 5.4 2.1]\n",
            " [6.7 3.1 5.6 2.4]\n",
            " [6.9 3.1 5.1 2.3]\n",
            " [5.8 2.7 5.1 1.9]\n",
            " [6.8 3.2 5.9 2.3]\n",
            " [6.7 3.3 5.7 2.5]\n",
            " [6.7 3.  5.2 2.3]\n",
            " [6.3 2.5 5.  1.9]\n",
            " [6.5 3.  5.2 2. ]\n",
            " [6.2 3.4 5.4 2.3]\n",
            " [5.9 3.  5.1 1.8]]\n",
            "[[0.  5.1 3.5 1.4 0.2]\n",
            " [0.  4.9 3.  1.4 0.2]\n",
            " [0.  4.7 3.2 1.3 0.2]\n",
            " [0.  4.6 3.1 1.5 0.2]\n",
            " [0.  5.  3.6 1.4 0.2]\n",
            " [0.  5.4 3.9 1.7 0.4]\n",
            " [0.  4.6 3.4 1.4 0.3]\n",
            " [0.  5.  3.4 1.5 0.2]\n",
            " [0.  4.4 2.9 1.4 0.2]\n",
            " [0.  4.9 3.1 1.5 0.1]\n",
            " [0.  5.4 3.7 1.5 0.2]\n",
            " [0.  4.8 3.4 1.6 0.2]\n",
            " [0.  4.8 3.  1.4 0.1]\n",
            " [0.  4.3 3.  1.1 0.1]\n",
            " [0.  5.8 4.  1.2 0.2]\n",
            " [0.  5.7 4.4 1.5 0.4]\n",
            " [0.  5.4 3.9 1.3 0.4]\n",
            " [0.  5.1 3.5 1.4 0.3]\n",
            " [0.  5.7 3.8 1.7 0.3]\n",
            " [0.  5.1 3.8 1.5 0.3]\n",
            " [0.  5.4 3.4 1.7 0.2]\n",
            " [0.  5.1 3.7 1.5 0.4]\n",
            " [0.  4.6 3.6 1.  0.2]\n",
            " [0.  5.1 3.3 1.7 0.5]\n",
            " [0.  4.8 3.4 1.9 0.2]\n",
            " [0.  5.  3.  1.6 0.2]\n",
            " [0.  5.  3.4 1.6 0.4]\n",
            " [0.  5.2 3.5 1.5 0.2]\n",
            " [0.  5.2 3.4 1.4 0.2]\n",
            " [0.  4.7 3.2 1.6 0.2]\n",
            " [0.  4.8 3.1 1.6 0.2]\n",
            " [0.  5.4 3.4 1.5 0.4]\n",
            " [0.  5.2 4.1 1.5 0.1]\n",
            " [0.  5.5 4.2 1.4 0.2]\n",
            " [0.  4.9 3.1 1.5 0.2]\n",
            " [0.  5.  3.2 1.2 0.2]\n",
            " [0.  5.5 3.5 1.3 0.2]\n",
            " [0.  4.9 3.6 1.4 0.1]\n",
            " [0.  4.4 3.  1.3 0.2]\n",
            " [0.  5.1 3.4 1.5 0.2]\n",
            " [0.  5.  3.5 1.3 0.3]\n",
            " [0.  4.5 2.3 1.3 0.3]\n",
            " [0.  4.4 3.2 1.3 0.2]\n",
            " [0.  5.  3.5 1.6 0.6]\n",
            " [0.  5.1 3.8 1.9 0.4]\n",
            " [0.  4.8 3.  1.4 0.3]\n",
            " [0.  5.1 3.8 1.6 0.2]\n",
            " [0.  4.6 3.2 1.4 0.2]\n",
            " [0.  5.3 3.7 1.5 0.2]\n",
            " [0.  5.  3.3 1.4 0.2]\n",
            " [1.  7.  3.2 4.7 1.4]\n",
            " [1.  6.4 3.2 4.5 1.5]\n",
            " [1.  6.9 3.1 4.9 1.5]\n",
            " [1.  5.5 2.3 4.  1.3]\n",
            " [1.  6.5 2.8 4.6 1.5]\n",
            " [1.  5.7 2.8 4.5 1.3]\n",
            " [1.  6.3 3.3 4.7 1.6]\n",
            " [1.  4.9 2.4 3.3 1. ]\n",
            " [1.  6.6 2.9 4.6 1.3]\n",
            " [1.  5.2 2.7 3.9 1.4]\n",
            " [1.  5.  2.  3.5 1. ]\n",
            " [1.  5.9 3.  4.2 1.5]\n",
            " [1.  6.  2.2 4.  1. ]\n",
            " [1.  6.1 2.9 4.7 1.4]\n",
            " [1.  5.6 2.9 3.6 1.3]\n",
            " [1.  6.7 3.1 4.4 1.4]\n",
            " [1.  5.6 3.  4.5 1.5]\n",
            " [1.  5.8 2.7 4.1 1. ]\n",
            " [1.  6.2 2.2 4.5 1.5]\n",
            " [1.  5.6 2.5 3.9 1.1]\n",
            " [1.  5.9 3.2 4.8 1.8]\n",
            " [1.  6.1 2.8 4.  1.3]\n",
            " [1.  6.3 2.5 4.9 1.5]\n",
            " [1.  6.1 2.8 4.7 1.2]\n",
            " [1.  6.4 2.9 4.3 1.3]\n",
            " [1.  6.6 3.  4.4 1.4]\n",
            " [1.  6.8 2.8 4.8 1.4]\n",
            " [1.  6.7 3.  5.  1.7]\n",
            " [1.  6.  2.9 4.5 1.5]\n",
            " [1.  5.7 2.6 3.5 1. ]\n",
            " [1.  5.5 2.4 3.8 1.1]\n",
            " [1.  5.5 2.4 3.7 1. ]\n",
            " [1.  5.8 2.7 3.9 1.2]\n",
            " [1.  6.  2.7 5.1 1.6]\n",
            " [1.  5.4 3.  4.5 1.5]\n",
            " [1.  6.  3.4 4.5 1.6]\n",
            " [1.  6.7 3.1 4.7 1.5]\n",
            " [1.  6.3 2.3 4.4 1.3]\n",
            " [1.  5.6 3.  4.1 1.3]\n",
            " [1.  5.5 2.5 4.  1.3]\n",
            " [1.  5.5 2.6 4.4 1.2]\n",
            " [1.  6.1 3.  4.6 1.4]\n",
            " [1.  5.8 2.6 4.  1.2]\n",
            " [1.  5.  2.3 3.3 1. ]\n",
            " [1.  5.6 2.7 4.2 1.3]\n",
            " [1.  5.7 3.  4.2 1.2]\n",
            " [1.  5.7 2.9 4.2 1.3]\n",
            " [1.  6.2 2.9 4.3 1.3]\n",
            " [1.  5.1 2.5 3.  1.1]\n",
            " [1.  5.7 2.8 4.1 1.3]\n",
            " [2.  6.3 3.3 6.  2.5]\n",
            " [2.  5.8 2.7 5.1 1.9]\n",
            " [2.  7.1 3.  5.9 2.1]\n",
            " [2.  6.3 2.9 5.6 1.8]\n",
            " [2.  6.5 3.  5.8 2.2]\n",
            " [2.  7.6 3.  6.6 2.1]\n",
            " [2.  4.9 2.5 4.5 1.7]\n",
            " [2.  7.3 2.9 6.3 1.8]\n",
            " [2.  6.7 2.5 5.8 1.8]\n",
            " [2.  7.2 3.6 6.1 2.5]\n",
            " [2.  6.5 3.2 5.1 2. ]\n",
            " [2.  6.4 2.7 5.3 1.9]\n",
            " [2.  6.8 3.  5.5 2.1]\n",
            " [2.  5.7 2.5 5.  2. ]\n",
            " [2.  5.8 2.8 5.1 2.4]\n",
            " [2.  6.4 3.2 5.3 2.3]\n",
            " [2.  6.5 3.  5.5 1.8]\n",
            " [2.  7.7 3.8 6.7 2.2]\n",
            " [2.  7.7 2.6 6.9 2.3]\n",
            " [2.  6.  2.2 5.  1.5]\n",
            " [2.  6.9 3.2 5.7 2.3]\n",
            " [2.  5.6 2.8 4.9 2. ]\n",
            " [2.  7.7 2.8 6.7 2. ]\n",
            " [2.  6.3 2.7 4.9 1.8]\n",
            " [2.  6.7 3.3 5.7 2.1]\n",
            " [2.  7.2 3.2 6.  1.8]\n",
            " [2.  6.2 2.8 4.8 1.8]\n",
            " [2.  6.1 3.  4.9 1.8]\n",
            " [2.  6.4 2.8 5.6 2.1]\n",
            " [2.  7.2 3.  5.8 1.6]\n",
            " [2.  7.4 2.8 6.1 1.9]\n",
            " [2.  7.9 3.8 6.4 2. ]\n",
            " [2.  6.4 2.8 5.6 2.2]\n",
            " [2.  6.3 2.8 5.1 1.5]\n",
            " [2.  6.1 2.6 5.6 1.4]\n",
            " [2.  7.7 3.  6.1 2.3]\n",
            " [2.  6.3 3.4 5.6 2.4]\n",
            " [2.  6.4 3.1 5.5 1.8]\n",
            " [2.  6.  3.  4.8 1.8]\n",
            " [2.  6.9 3.1 5.4 2.1]\n",
            " [2.  6.7 3.1 5.6 2.4]\n",
            " [2.  6.9 3.1 5.1 2.3]\n",
            " [2.  5.8 2.7 5.1 1.9]\n",
            " [2.  6.8 3.2 5.9 2.3]\n",
            " [2.  6.7 3.3 5.7 2.5]\n",
            " [2.  6.7 3.  5.2 2.3]\n",
            " [2.  6.3 2.5 5.  1.9]\n",
            " [2.  6.5 3.  5.2 2. ]\n",
            " [2.  6.2 3.4 5.4 2.3]\n",
            " [2.  5.9 3.  5.1 1.8]]\n",
            "+-----+-----------------+\n",
            "|label|         features|\n",
            "+-----+-----------------+\n",
            "|    0|[5.1,3.5,1.4,0.2]|\n",
            "|    0|[4.9,3.0,1.4,0.2]|\n",
            "|    0|[4.7,3.2,1.3,0.2]|\n",
            "|    0|[4.6,3.1,1.5,0.2]|\n",
            "|    0|[5.0,3.6,1.4,0.2]|\n",
            "|    0|[5.4,3.9,1.7,0.4]|\n",
            "|    0|[4.6,3.4,1.4,0.3]|\n",
            "|    0|[5.0,3.4,1.5,0.2]|\n",
            "|    0|[4.4,2.9,1.4,0.2]|\n",
            "|    0|[4.9,3.1,1.5,0.1]|\n",
            "|    0|[5.4,3.7,1.5,0.2]|\n",
            "|    0|[4.8,3.4,1.6,0.2]|\n",
            "|    0|[4.8,3.0,1.4,0.1]|\n",
            "|    0|[4.3,3.0,1.1,0.1]|\n",
            "|    0|[5.8,4.0,1.2,0.2]|\n",
            "|    0|[5.7,4.4,1.5,0.4]|\n",
            "|    0|[5.4,3.9,1.3,0.4]|\n",
            "|    0|[5.1,3.5,1.4,0.3]|\n",
            "|    0|[5.7,3.8,1.7,0.3]|\n",
            "|    0|[5.1,3.8,1.5,0.3]|\n",
            "|    0|[5.4,3.4,1.7,0.2]|\n",
            "|    0|[5.1,3.7,1.5,0.4]|\n",
            "|    0|[4.6,3.6,1.0,0.2]|\n",
            "|    0|[5.1,3.3,1.7,0.5]|\n",
            "|    0|[4.8,3.4,1.9,0.2]|\n",
            "|    0|[5.0,3.0,1.6,0.2]|\n",
            "|    0|[5.0,3.4,1.6,0.4]|\n",
            "|    0|[5.2,3.5,1.5,0.2]|\n",
            "|    0|[5.2,3.4,1.4,0.2]|\n",
            "|    0|[4.7,3.2,1.6,0.2]|\n",
            "|    0|[4.8,3.1,1.6,0.2]|\n",
            "|    0|[5.4,3.4,1.5,0.4]|\n",
            "|    0|[5.2,4.1,1.5,0.1]|\n",
            "|    0|[5.5,4.2,1.4,0.2]|\n",
            "|    0|[4.9,3.1,1.5,0.2]|\n",
            "|    0|[5.0,3.2,1.2,0.2]|\n",
            "|    0|[5.5,3.5,1.3,0.2]|\n",
            "|    0|[4.9,3.6,1.4,0.1]|\n",
            "|    0|[4.4,3.0,1.3,0.2]|\n",
            "|    0|[5.1,3.4,1.5,0.2]|\n",
            "|    0|[5.0,3.5,1.3,0.3]|\n",
            "|    0|[4.5,2.3,1.3,0.3]|\n",
            "|    0|[4.4,3.2,1.3,0.2]|\n",
            "|    0|[5.0,3.5,1.6,0.6]|\n",
            "|    0|[5.1,3.8,1.9,0.4]|\n",
            "|    0|[4.8,3.0,1.4,0.3]|\n",
            "|    0|[5.1,3.8,1.6,0.2]|\n",
            "|    0|[4.6,3.2,1.4,0.2]|\n",
            "|    0|[5.3,3.7,1.5,0.2]|\n",
            "|    0|[5.0,3.3,1.4,0.2]|\n",
            "|    1|[7.0,3.2,4.7,1.4]|\n",
            "|    1|[6.4,3.2,4.5,1.5]|\n",
            "|    1|[6.9,3.1,4.9,1.5]|\n",
            "|    1|[5.5,2.3,4.0,1.3]|\n",
            "|    1|[6.5,2.8,4.6,1.5]|\n",
            "|    1|[5.7,2.8,4.5,1.3]|\n",
            "|    1|[6.3,3.3,4.7,1.6]|\n",
            "|    1|[4.9,2.4,3.3,1.0]|\n",
            "|    1|[6.6,2.9,4.6,1.3]|\n",
            "|    1|[5.2,2.7,3.9,1.4]|\n",
            "|    1|[5.0,2.0,3.5,1.0]|\n",
            "|    1|[5.9,3.0,4.2,1.5]|\n",
            "|    1|[6.0,2.2,4.0,1.0]|\n",
            "|    1|[6.1,2.9,4.7,1.4]|\n",
            "|    1|[5.6,2.9,3.6,1.3]|\n",
            "|    1|[6.7,3.1,4.4,1.4]|\n",
            "|    1|[5.6,3.0,4.5,1.5]|\n",
            "|    1|[5.8,2.7,4.1,1.0]|\n",
            "|    1|[6.2,2.2,4.5,1.5]|\n",
            "|    1|[5.6,2.5,3.9,1.1]|\n",
            "|    1|[5.9,3.2,4.8,1.8]|\n",
            "|    1|[6.1,2.8,4.0,1.3]|\n",
            "|    1|[6.3,2.5,4.9,1.5]|\n",
            "|    1|[6.1,2.8,4.7,1.2]|\n",
            "|    1|[6.4,2.9,4.3,1.3]|\n",
            "|    1|[6.6,3.0,4.4,1.4]|\n",
            "|    1|[6.8,2.8,4.8,1.4]|\n",
            "|    1|[6.7,3.0,5.0,1.7]|\n",
            "|    1|[6.0,2.9,4.5,1.5]|\n",
            "|    1|[5.7,2.6,3.5,1.0]|\n",
            "|    1|[5.5,2.4,3.8,1.1]|\n",
            "|    1|[5.5,2.4,3.7,1.0]|\n",
            "|    1|[5.8,2.7,3.9,1.2]|\n",
            "|    1|[6.0,2.7,5.1,1.6]|\n",
            "|    1|[5.4,3.0,4.5,1.5]|\n",
            "|    1|[6.0,3.4,4.5,1.6]|\n",
            "|    1|[6.7,3.1,4.7,1.5]|\n",
            "|    1|[6.3,2.3,4.4,1.3]|\n",
            "|    1|[5.6,3.0,4.1,1.3]|\n",
            "|    1|[5.5,2.5,4.0,1.3]|\n",
            "|    1|[5.5,2.6,4.4,1.2]|\n",
            "|    1|[6.1,3.0,4.6,1.4]|\n",
            "|    1|[5.8,2.6,4.0,1.2]|\n",
            "|    1|[5.0,2.3,3.3,1.0]|\n",
            "|    1|[5.6,2.7,4.2,1.3]|\n",
            "|    1|[5.7,3.0,4.2,1.2]|\n",
            "|    1|[5.7,2.9,4.2,1.3]|\n",
            "|    1|[6.2,2.9,4.3,1.3]|\n",
            "|    1|[5.1,2.5,3.0,1.1]|\n",
            "|    1|[5.7,2.8,4.1,1.3]|\n",
            "|    2|[6.3,3.3,6.0,2.5]|\n",
            "|    2|[5.8,2.7,5.1,1.9]|\n",
            "|    2|[7.1,3.0,5.9,2.1]|\n",
            "|    2|[6.3,2.9,5.6,1.8]|\n",
            "|    2|[6.5,3.0,5.8,2.2]|\n",
            "|    2|[7.6,3.0,6.6,2.1]|\n",
            "|    2|[4.9,2.5,4.5,1.7]|\n",
            "|    2|[7.3,2.9,6.3,1.8]|\n",
            "|    2|[6.7,2.5,5.8,1.8]|\n",
            "|    2|[7.2,3.6,6.1,2.5]|\n",
            "|    2|[6.5,3.2,5.1,2.0]|\n",
            "|    2|[6.4,2.7,5.3,1.9]|\n",
            "|    2|[6.8,3.0,5.5,2.1]|\n",
            "|    2|[5.7,2.5,5.0,2.0]|\n",
            "|    2|[5.8,2.8,5.1,2.4]|\n",
            "|    2|[6.4,3.2,5.3,2.3]|\n",
            "|    2|[6.5,3.0,5.5,1.8]|\n",
            "|    2|[7.7,3.8,6.7,2.2]|\n",
            "|    2|[7.7,2.6,6.9,2.3]|\n",
            "|    2|[6.0,2.2,5.0,1.5]|\n",
            "|    2|[6.9,3.2,5.7,2.3]|\n",
            "|    2|[5.6,2.8,4.9,2.0]|\n",
            "|    2|[7.7,2.8,6.7,2.0]|\n",
            "|    2|[6.3,2.7,4.9,1.8]|\n",
            "|    2|[6.7,3.3,5.7,2.1]|\n",
            "|    2|[7.2,3.2,6.0,1.8]|\n",
            "|    2|[6.2,2.8,4.8,1.8]|\n",
            "|    2|[6.1,3.0,4.9,1.8]|\n",
            "|    2|[6.4,2.8,5.6,2.1]|\n",
            "|    2|[7.2,3.0,5.8,1.6]|\n",
            "|    2|[7.4,2.8,6.1,1.9]|\n",
            "|    2|[7.9,3.8,6.4,2.0]|\n",
            "|    2|[6.4,2.8,5.6,2.2]|\n",
            "|    2|[6.3,2.8,5.1,1.5]|\n",
            "|    2|[6.1,2.6,5.6,1.4]|\n",
            "|    2|[7.7,3.0,6.1,2.3]|\n",
            "|    2|[6.3,3.4,5.6,2.4]|\n",
            "|    2|[6.4,3.1,5.5,1.8]|\n",
            "|    2|[6.0,3.0,4.8,1.8]|\n",
            "|    2|[6.9,3.1,5.4,2.1]|\n",
            "|    2|[6.7,3.1,5.6,2.4]|\n",
            "|    2|[6.9,3.1,5.1,2.3]|\n",
            "|    2|[5.8,2.7,5.1,1.9]|\n",
            "|    2|[6.8,3.2,5.9,2.3]|\n",
            "|    2|[6.7,3.3,5.7,2.5]|\n",
            "|    2|[6.7,3.0,5.2,2.3]|\n",
            "|    2|[6.3,2.5,5.0,1.9]|\n",
            "|    2|[6.5,3.0,5.2,2.0]|\n",
            "|    2|[6.2,3.4,5.4,2.3]|\n",
            "|    2|[5.9,3.0,5.1,1.8]|\n",
            "+-----+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Linear Regression**"
      ],
      "metadata": {
        "id": "LG3S3MOburPo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.regression import LinearRegression\n",
        "\n",
        "#create instance of linear regression\n",
        "#The learning objective is to minimize the specified loss function, with regularization. This supports two kinds of loss:\n",
        "#squaredError (a.k.a squared loss)\n",
        "#least squares regularization\n",
        "\n",
        "lr = LinearRegression(featuresCol = 'features', maxIter=10, regParam=0.3, loss='squaredError')\n",
        "\n",
        "# Fit the model\n",
        "lr_model = lr.fit(mydf)\n",
        "\n",
        "# Print the coefficients and intercept for linear regression\n",
        "print(\"Coefficients: \" + str(lr_model.coefficients))\n",
        "print(\"Intercept: \" + str(lr_model.intercept))\n",
        "\n",
        "# Summarize the model over the training set and print out some metrics\n",
        "trainingSummary = lr_model.summary\n",
        "print(\"RMSE: %f\" % trainingSummary.rootMeanSquaredError)\n",
        "\n",
        "#predict the data with this linear regression model\n",
        "test_data_1=my_test.collect()[0]\n",
        "print(\"For test data 1 prediction: %f  Original: %d\" %(lr_model.predict(test_data_1.features),test_data_1.label))\n",
        "\n",
        "test_data_2=my_test.collect()[2]\n",
        "print(\"For test data 2 prediction: %f  Original: %d\" %(lr_model.predict(test_data_2.features),test_data_2.label))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9UddLZaYuvEO",
        "outputId": "fbd8bee6-85b8-4e1e-8498-3bc6f411d70d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coefficients: [0.1454035169766318,-0.19609029124319305,0.14419140589678436,0.3921800360534983]\n",
            "Intercept: -0.2623537270395407\n",
            "RMSE: 0.258500\n",
            "For test data 1 prediction: 0.093346  Original: 0\n",
            "For test data 2 prediction: 1.366081  Original: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **K-means Clustering**"
      ],
      "metadata": {
        "id": "_sbWvqxEt8Ws"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#numpy to spark dataframe\n",
        "import numpy as np\n",
        "from pyspark.ml.linalg import Vectors\n",
        "\n",
        "from pyspark.ml.clustering import KMeans\n",
        "from pyspark.ml.evaluation import ClusteringEvaluator\n",
        "# Trains a k-means model.\n",
        "kmeans = KMeans().setSeed(1).setK(3).setDistanceMeasure('euclidean')\n",
        "\n",
        "\n",
        "km_model = kmeans.fit(mydf)\n",
        "\n",
        "# Evaluate clustering by computing Silhouette score\n",
        "evaluator = ClusteringEvaluator(metricName='silhouette', distanceMeasure='squaredEuclidean')\n",
        "silhouette = evaluator.evaluate(predictions)\n",
        "print(\"Silhouette with squared euclidean distance = \" + str(silhouette))\n",
        "\n",
        "# Shows the result.\n",
        "centers = km_model.clusterCenters()\n",
        "print(\"Cluster Centers: \")\n",
        "for center in centers:\n",
        "    print(center)\n",
        "\n",
        "#prediction:\n",
        "\n",
        "test_data_1=my_test.collect()[0]\n",
        "print(\"For test data 1 predicted cluster: %f  Original cluster: %d\" %(km_model.predict(test_data_1.features),test_data_1.label))\n",
        "\n",
        "test_data_2=my_test.collect()[2]\n",
        "print(\"For test data 2 predicted cluster: %f  Original cluster: %d\" %(km_model.predict(test_data_2.features),test_data_2.label))\n",
        "\n",
        "test_data_3=my_test.collect()[4]\n",
        "print(\"For test data 3 predicted cluster: %f  Original cluster: %d\" %(km_model.predict(test_data_3.features),test_data_2.label))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VqNElB-huR7O",
        "outputId": "5868d8c8-f619-48b4-afa9-26e054e2567a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Silhouette with squared euclidean distance = 0.7344130579787836\n",
            "Cluster Centers: \n",
            "[5.88360656 2.74098361 4.38852459 1.43442623]\n",
            "[5.006 3.428 1.462 0.246]\n",
            "[6.85384615 3.07692308 5.71538462 2.05384615]\n",
            "For test data 1 predicted cluster: 1.000000  Original cluster: 0\n",
            "For test data 2 predicted cluster: 0.000000  Original cluster: 1\n",
            "For test data 3 predicted cluster: 2.000000  Original cluster: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Logistic Regression Classifier**"
      ],
      "metadata": {
        "id": "TJ6ivCWuewb1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "# Create a LogisticRegression instance. This instance is an Estimator.\n",
        "lr = LogisticRegression(maxIter=30, regParam=0.01)\n",
        "\n",
        "# Learn a LogisticRegression model. This uses the parameters stored in lr.\n",
        "lrc = lr.fit(mydf)\n",
        "\n",
        "# Since model1 is a Model (i.e., a transformer produced by an Estimator),\n",
        "# extractParamMap() prints the parameters this LogisticRegression instance used during fit().\n",
        "print(\"Model was fit using parameters: \")\n",
        "print(lrc.extractParamMap())\n",
        "print(\"\\n\\n\")\n",
        "\n",
        "# Make predictions on test data using the Transformer.transform() method.\n",
        "# LogisticRegression.transform will only use the 'features' column.\n",
        "# Note that model2.transform() outputs a \"myProbability\" column instead of the usual\n",
        "# 'probability' column since we renamed the lr.probabilityCol parameter previously.\n",
        "# compute accuracy on the test set\n",
        "result = lrc.transform(my_test)\n",
        "predictionAndLabels = result.select('features', 'label', 'prediction', 'probability')\n",
        "predictionAndLabels.show()\n",
        "\n",
        "evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
        "print(\"Test set accuracy = \" + str(evaluator.evaluate(predictionAndLabels)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPJP_KWD5oPD",
        "outputId": "64f03d8c-8c99-47cd-8f01-af36680fdbe9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model was fit using parameters: \n",
            "{Param(parent='LogisticRegression_7a23b29da942', name='aggregationDepth', doc='suggested depth for treeAggregate (>= 2).'): 2, Param(parent='LogisticRegression_7a23b29da942', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.0, Param(parent='LogisticRegression_7a23b29da942', name='family', doc='The name of family which is a description of the label distribution to be used in the model. Supported options: auto, binomial, multinomial'): 'auto', Param(parent='LogisticRegression_7a23b29da942', name='featuresCol', doc='features column name.'): 'features', Param(parent='LogisticRegression_7a23b29da942', name='fitIntercept', doc='whether to fit an intercept term.'): True, Param(parent='LogisticRegression_7a23b29da942', name='labelCol', doc='label column name.'): 'label', Param(parent='LogisticRegression_7a23b29da942', name='maxBlockSizeInMB', doc='maximum memory in MB for stacking input data into blocks. Data is stacked within partitions. If more than remaining data size in a partition then it is adjusted to the data size. Default 0.0 represents choosing optimal value, depends on specific algorithm. Must be >= 0.'): 0.0, Param(parent='LogisticRegression_7a23b29da942', name='maxIter', doc='max number of iterations (>= 0).'): 30, Param(parent='LogisticRegression_7a23b29da942', name='predictionCol', doc='prediction column name.'): 'prediction', Param(parent='LogisticRegression_7a23b29da942', name='probabilityCol', doc='Column name for predicted class conditional probabilities. Note: Not all models output well-calibrated probability estimates! These probabilities should be treated as confidences, not precise probabilities.'): 'probability', Param(parent='LogisticRegression_7a23b29da942', name='rawPredictionCol', doc='raw prediction (a.k.a. confidence) column name.'): 'rawPrediction', Param(parent='LogisticRegression_7a23b29da942', name='regParam', doc='regularization parameter (>= 0).'): 0.01, Param(parent='LogisticRegression_7a23b29da942', name='standardization', doc='whether to standardize the training features before fitting the model.'): True, Param(parent='LogisticRegression_7a23b29da942', name='threshold', doc='Threshold in binary classification prediction, in range [0, 1]. If threshold and thresholds are both set, they must match.e.g. if threshold is p, then thresholds must be equal to [1-p, p].'): 0.5, Param(parent='LogisticRegression_7a23b29da942', name='tol', doc='the convergence tolerance for iterative algorithms (>= 0).'): 1e-06}\n",
            "\n",
            "\n",
            "\n",
            "+-----------------+-----+----------+--------------------+\n",
            "|         features|label|prediction|         probability|\n",
            "+-----------------+-----+----------+--------------------+\n",
            "|[4.6,3.1,1.5,0.2]|  0.0|       0.0|[0.96537479797300...|\n",
            "|[5.4,3.7,1.5,0.2]|  0.0|       0.0|[0.97935560440879...|\n",
            "|[5.9,3.2,4.8,1.8]|  1.0|       2.0|[0.01760858433536...|\n",
            "|[6.3,2.5,4.9,1.5]|  1.0|       1.0|[0.00156796562015...|\n",
            "|[6.7,3.3,5.7,2.5]|  2.0|       2.0|[5.01260690000953...|\n",
            "+-----------------+-----+----------+--------------------+\n",
            "\n",
            "Test set accuracy = 0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Naive Bayes Classifier**"
      ],
      "metadata": {
        "id": "6H4AmSJl9jf_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import NaiveBayes\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "#data modeling\n",
        "nb = NaiveBayes(smoothing=0.5, modelType=\"multinomial\")\n",
        "nb = nb.fit(mydf)\n",
        "\n",
        "#prediction\n",
        "result = nb.transform(my_test)\n",
        "predictionAndLabels = result.select('features', 'label', 'prediction', 'probability')\n",
        "predictionAndLabels.show()\n",
        "\n",
        "# evaluation: compute accuracy on the test set\n",
        "evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
        "print(\"Test set accuracy = \" + str(evaluator.evaluate(predictionAndLabels)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7eb3RWpXhYGP",
        "outputId": "197955be-a714-424e-edf9-6649d1169804"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+-----+----------+--------------------+\n",
            "|         features|label|prediction|         probability|\n",
            "+-----------------+-----+----------+--------------------+\n",
            "|[4.6,3.1,1.5,0.2]|  0.0|       0.0|[0.66753665375089...|\n",
            "|[5.4,3.7,1.5,0.2]|  0.0|       0.0|[0.77079040565310...|\n",
            "|[5.9,3.2,4.8,1.8]|  1.0|       2.0|[0.02305501121933...|\n",
            "|[6.3,2.5,4.9,1.5]|  1.0|       2.0|[0.02328585154573...|\n",
            "|[6.7,3.3,5.7,2.5]|  2.0|       2.0|[0.00542491580818...|\n",
            "+-----------------+-----+----------+--------------------+\n",
            "\n",
            "Test set accuracy = 0.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Decision Tree Classifier**"
      ],
      "metadata": {
        "id": "COQ169cuxzIg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import DecisionTreeClassifier\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "#create instance\n",
        "dt = DecisionTreeClassifier(featuresCol = 'features', labelCol = 'label', maxDepth = 3)\n",
        "#fit the data\n",
        "dtModel = dt.fit(mydf)\n",
        "\n",
        "\n",
        "# prediction\n",
        "result = dtModel.transform(my_test)\n",
        "predictionAndLabels = result.select('features', 'label', 'prediction')\n",
        "predictionAndLabels.show()\n",
        "\n",
        "#evaluation\n",
        "evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
        "print(\"Test set accuracy = \" + str(evaluator.evaluate(predictionAndLabels)))"
      ],
      "metadata": {
        "id": "3OQyEj7gx42l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f235d148-2761-4b95-b458-9d85dd5786d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+-----+----------+\n",
            "|         features|label|prediction|\n",
            "+-----------------+-----+----------+\n",
            "|[4.6,3.1,1.5,0.2]|  0.0|       0.0|\n",
            "|[5.4,3.7,1.5,0.2]|  0.0|       0.0|\n",
            "|[5.9,3.2,4.8,1.8]|  1.0|       2.0|\n",
            "|[6.3,2.5,4.9,1.5]|  1.0|       1.0|\n",
            "|[6.7,3.3,5.7,2.5]|  2.0|       2.0|\n",
            "+-----------------+-----+----------+\n",
            "\n",
            "Test set accuracy = 0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Support Vector Machine**"
      ],
      "metadata": {
        "id": "Y9JsoLs_MOld"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark import SparkContext\n",
        "from pyspark.sql import SQLContext\n",
        "from pyspark.ml.classification import LinearSVC\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "\n",
        "sqlContext = SQLContext(spark)\n",
        "\n",
        "mydf2 = sqlContext.createDataFrame(mydf.head(100), mydf.schema)\n",
        "\n",
        "#data split\n",
        "(train, test) = mydf2.randomSplit([0.8, 0.2])\n",
        "\n",
        "#create instance\n",
        "lsvc = LinearSVC(labelCol=\"label\", maxIter=50)\n",
        "\n",
        "#fit the data\n",
        "lsvc = lsvc.fit(train)\n",
        "\n",
        "# preeiction\n",
        "result = lsvc.transform(my_test)\n",
        "predictionAndLabels = result.select('features', 'label', 'prediction', 'rawPrediction')\n",
        "predictionAndLabels.show()\n",
        "\n",
        "#evaluation\n",
        "evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
        "print(\"Test set accuracy = \" + str(evaluator.evaluate(predictionAndLabels)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S01yabr3c_EZ",
        "outputId": "abec94c0-6e50-4369-e39b-143cd57e3b2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pyspark/sql/context.py:79: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
            "  FutureWarning\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+-----+----------+--------------------+\n",
            "|         features|label|prediction|       rawPrediction|\n",
            "+-----------------+-----+----------+--------------------+\n",
            "|[4.6,3.1,1.5,0.2]|  0.0|       0.0|[3.16205620969785...|\n",
            "|[5.4,3.7,1.5,0.2]|  0.0|       0.0|[3.84664243908044...|\n",
            "|[5.9,3.2,4.8,1.8]|  1.0|       1.0|[-3.5641785867991...|\n",
            "|[6.3,2.5,4.9,1.5]|  1.0|       1.0|[-4.8379166733543...|\n",
            "|[6.7,3.3,5.7,2.5]|  2.0|       1.0|[-6.1352672214111...|\n",
            "+-----------------+-----+----------+--------------------+\n",
            "\n",
            "Test set accuracy = 0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Multilayer perceptron classifier**\n"
      ],
      "metadata": {
        "id": "EDUGqk5lMUjE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "# Split the data into train and test\n",
        "splits = mydf.randomSplit([0.6, 0.4], 1234)   #randomSplit: Randomly splits this DataFrame with the provided weights.\n",
        "train = splits[0]\n",
        "test = splits[1]\n",
        "\n",
        "# specify layers for the neural network:\n",
        "# input layer of size 4 (features), four intermediate of size 8, 10, 8 and 4\n",
        "# and output of size 3 (classes)\n",
        "#total number of layers= 5\n",
        "#layers = [4, 8, 10, 8, 4, 3]\n",
        "layers = [4, 2, 3]\n",
        "\n",
        "# create the trainer and set its parameters\n",
        "trainer = MultilayerPerceptronClassifier(maxIter=100, layers=layers, blockSize=128, seed=1234)\n",
        "\n",
        "# train the model\n",
        "model = trainer.fit(train)\n",
        "\n",
        "# compute accuracy on the test set\n",
        "result = model.transform(my_test)\n",
        "predictionAndLabels = result.select('features', 'label', 'prediction', 'probability')#(\"prediction\", \"label\")\n",
        "predictionAndLabels.show()\n",
        "\n",
        "evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
        "print(\"Test set accuracy = \" + str(evaluator.evaluate(predictionAndLabels)))\n"
      ],
      "metadata": {
        "id": "Y8UZU2xQRQgf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f077e31-e0d9-4ce5-f3b7-65d6ccd8ba66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+-----+----------+--------------------+\n",
            "|         features|label|prediction|         probability|\n",
            "+-----------------+-----+----------+--------------------+\n",
            "|[4.6,3.1,1.5,0.2]|  0.0|       0.0|[1.0,8.4350926179...|\n",
            "|[5.4,3.7,1.5,0.2]|  0.0|       0.0|[1.0,8.4350926179...|\n",
            "|[5.9,3.2,4.8,1.8]|  1.0|       1.0|[2.56442352185225...|\n",
            "|[6.3,2.5,4.9,1.5]|  1.0|       1.0|[2.56442352185225...|\n",
            "|[6.7,3.3,5.7,2.5]|  2.0|       1.0|[2.56442352185225...|\n",
            "+-----------------+-----+----------+--------------------+\n",
            "\n",
            "Test set accuracy = 0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **PCA**"
      ],
      "metadata": {
        "id": "e5yKlUoOZEdZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import PCA, VectorAssembler, StandardScaler\n",
        "\n",
        "#create feature vector\n",
        "feature_vectors = mydf.select(\"features\")\n",
        "feature_vectors.show()\n",
        "\n",
        "#standardize the features\n",
        "scaler = StandardScaler(\n",
        "    inputCol = 'features', \n",
        "    outputCol = 'scaledFeatures',\n",
        "    withMean = True,\n",
        "    withStd = True\n",
        ").fit(feature_vectors)\n",
        "\n",
        "# when we transform the dataframe, the old\n",
        "# feature will still remain in it\n",
        "df_scaled = scaler.transform(feature_vectors)\n",
        "df_scaled.show()\n",
        "\n",
        "# build PCA model\n",
        "n_components = 2\n",
        "pca = PCA(\n",
        "    k = n_components, \n",
        "    inputCol = 'scaledFeatures', \n",
        "    outputCol = 'pcaFeatures'\n",
        ").fit(df_scaled)\n",
        "\n",
        "df_pca = pca.transform(df_scaled)\n",
        "print('Explained Variance Ratio', pca.explainedVariance.toArray())\n",
        "df_pca.show(6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dcje0zVgYwLV",
        "outputId": "b296fbf3-858d-4089-d4cc-f09ddbe1aae1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+\n",
            "|         features|\n",
            "+-----------------+\n",
            "|[5.1,3.5,1.4,0.2]|\n",
            "|[4.9,3.0,1.4,0.2]|\n",
            "|[4.7,3.2,1.3,0.2]|\n",
            "|[4.6,3.1,1.5,0.2]|\n",
            "|[5.0,3.6,1.4,0.2]|\n",
            "|[5.4,3.9,1.7,0.4]|\n",
            "|[4.6,3.4,1.4,0.3]|\n",
            "|[5.0,3.4,1.5,0.2]|\n",
            "|[4.4,2.9,1.4,0.2]|\n",
            "|[4.9,3.1,1.5,0.1]|\n",
            "|[5.4,3.7,1.5,0.2]|\n",
            "|[4.8,3.4,1.6,0.2]|\n",
            "|[4.8,3.0,1.4,0.1]|\n",
            "|[4.3,3.0,1.1,0.1]|\n",
            "|[5.8,4.0,1.2,0.2]|\n",
            "|[5.7,4.4,1.5,0.4]|\n",
            "|[5.4,3.9,1.3,0.4]|\n",
            "|[5.1,3.5,1.4,0.3]|\n",
            "|[5.7,3.8,1.7,0.3]|\n",
            "|[5.1,3.8,1.5,0.3]|\n",
            "+-----------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "+-----------------+--------------------+\n",
            "|         features|      scaledFeatures|\n",
            "+-----------------+--------------------+\n",
            "|[5.1,3.5,1.4,0.2]|[-0.8976738791967...|\n",
            "|[4.9,3.0,1.4,0.2]|[-1.1392004834649...|\n",
            "|[4.7,3.2,1.3,0.2]|[-1.3807270877331...|\n",
            "|[4.6,3.1,1.5,0.2]|[-1.5014903898672...|\n",
            "|[5.0,3.6,1.4,0.2]|[-1.0184371813308...|\n",
            "|[5.4,3.9,1.7,0.4]|[-0.5353839727944...|\n",
            "|[4.6,3.4,1.4,0.3]|[-1.5014903898672...|\n",
            "|[5.0,3.4,1.5,0.2]|[-1.0184371813308...|\n",
            "|[4.4,2.9,1.4,0.2]|[-1.7430169941354...|\n",
            "|[4.9,3.1,1.5,0.1]|[-1.1392004834649...|\n",
            "|[5.4,3.7,1.5,0.2]|[-0.5353839727944...|\n",
            "|[4.8,3.4,1.6,0.2]|[-1.2599637855990...|\n",
            "|[4.8,3.0,1.4,0.1]|[-1.2599637855990...|\n",
            "|[4.3,3.0,1.1,0.1]|[-1.8637802962695...|\n",
            "|[5.8,4.0,1.2,0.2]|[-0.0523307642581...|\n",
            "|[5.7,4.4,1.5,0.4]|[-0.1730940663922...|\n",
            "|[5.4,3.9,1.3,0.4]|[-0.5353839727944...|\n",
            "|[5.1,3.5,1.4,0.3]|[-0.8976738791967...|\n",
            "|[5.7,3.8,1.7,0.3]|[-0.1730940663922...|\n",
            "|[5.1,3.8,1.5,0.3]|[-0.8976738791967...|\n",
            "+-----------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "Explained Variance Ratio [0.72962445 0.22850762]\n",
            "+-----------------+--------------------+--------------------+\n",
            "|         features|      scaledFeatures|         pcaFeatures|\n",
            "+-----------------+--------------------+--------------------+\n",
            "|[5.1,3.5,1.4,0.2]|[-0.8976738791967...|[2.25714117564811...|\n",
            "|[4.9,3.0,1.4,0.2]|[-1.1392004834649...|[2.07401301519962...|\n",
            "|[4.7,3.2,1.3,0.2]|[-1.3807270877331...|[2.35633511180617...|\n",
            "|[4.6,3.1,1.5,0.2]|[-1.5014903898672...|[2.29170678586969...|\n",
            "|[5.0,3.6,1.4,0.2]|[-1.0184371813308...|[2.38186270441693...|\n",
            "|[5.4,3.9,1.7,0.4]|[-0.5353839727944...|[2.06870060846769...|\n",
            "+-----------------+--------------------+--------------------+\n",
            "only showing top 6 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Notice that unlike scikit-learn, we use transform on the dataframe at hand for all ML models' class after fitting it (calling .fit on the dataframe). This will return the result in a new column, where the name is specified by the outputCol argument in the ML models' class.\n",
        "#We can convert it back to a numpy array by extracting the pcaFeatures column from each row, and use collect to bring the entire dataset back to a single machine.\n",
        "\n",
        "# not sure if this is the best way to do it\n",
        "X_pca = df_pca.rdd.map(lambda row: row.pcaFeatures).collect()\n",
        "X_pca = np.array(X_pca)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "# change default style figure and font size\n",
        "plt.style.use('fivethirtyeight')\n",
        "plt.rcParams['figure.figsize'] = 8, 6\n",
        "plt.rcParams['font.size'] = 12\n",
        "\n",
        "\n",
        "def plot_iris_pca(X_pca, y):\n",
        "    \"\"\"a scatter plot of the 2-dimensional iris data\"\"\"\n",
        "    markers = 's', 'x', 'o'\n",
        "    colors = list(plt.rcParams['axes.prop_cycle'])\n",
        "    target = np.unique(y)\n",
        "    for idx, (t, m) in enumerate(zip(target, markers)):\n",
        "        subset = X_pca[y == t]\n",
        "        plt.scatter(subset[:, 0], subset[:, 1], s = 50,\n",
        "                    c = colors[idx]['color'], label = t, marker = m)\n",
        "\n",
        "    plt.xlabel('PC 1')\n",
        "    plt.ylabel('PC 2')\n",
        "    plt.legend(loc = 'lower left')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plot_iris_pca(X_pca, groundtruth)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "id": "THhIFAr8fkxi",
        "outputId": "b4ab12dc-9c7b-4a49-ebfe-5bf0a40e5604"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}